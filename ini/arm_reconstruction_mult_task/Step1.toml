
[config]
input = [
  "volume",
  "label"
]

logging = [
  '__train_iteration__', 
  'train.loss_reconstruct_volume_reduce', 'valid.loss_reconstruct_volume_reduce',
  'train.loss_reconstruct_label_reduce', 'valid.loss_reconstruct_label_reduce',
  'train.loss', 'valid.loss'
]
logging_weights = [
  "", 
  "multi_task_combine.sigma_0", "multi_task_combine.sigma_0", 
  "multi_task_combine.sigma_1", "multi_task_combine.sigma_1", 
  "", ""
]

archive_loss = 'loss'
archive_nodes = ['CAE']
optimizing_loss = ['loss']

[hyper_parameter]
n_encode_dim = 512
n_layers = 3
volume_gaussian_sigma = 20
label_gaussian_sigma = 0.2
n_res_layers = 4

[[process]]
label  = "CAE"
type   = "network.cae"
update = "loss"

# Arguments
n_dim = 3
n_tasks = 2
in_channel = 5
out_channel = [1, 4]
encode_dim = "${hyper_parameter.n_encode_dim}"
dropout = "dropout"
use_batch_norm = true
n_layers = "${hyper_parameter.n_layers}"
latent_activation = false # If true, the sparse penalty is avaiable.

[[process]]
label="multi_task_combine"
loss_types=["euclidean", "softmax_cross_entropy"]
#initialize=[1.0, 20.0] # this weight will be reciprocal squared value.
type   = "network.multi_task_loss"

[[network]]
input="volume"
process="expand_dims"
output="volume_expanded"
axis=1

[[network]]
input=["volume_expanded", "label"]
process="to_gpu"
output=["gpu_volume", "gpu_f_label"]

# Generate label probability
[[network]]
input="gpu_f_label"
process="cast_type"
dtype='int32'
output="gpu_label"

[[network]]
input = "gpu_label"
process= "label_to_probability"
output = "gpu_label_probs"

n_channel = 4

## Apply gaussian noise
[[network]]
input = "gpu_volume"
process = "apply_gaussian_noise"
output = "gpu_noisy_volume"

sigma = "${hyper_parameter.volume_gaussian_sigma}"

[[network]]
input = "gpu_label_probs"
process = "apply_gaussian_noise"
output = "gpu_noisy_label_probs"

sigma = "${hyper_parameter.label_gaussian_sigma}"
clip = [0.0, 1.0]

## Concatenate volume and label probs.
[[network]]
input = ["gpu_noisy_volume", "gpu_noisy_label_probs"]
process= "concat"
output = "gpu_noisy_mix_volume"

## Reconstruct label
[[network]]
input="gpu_noisy_mix_volume"
label="CAE"
process="CAE"
output=["gpu_reconstruct_volume", "gpu_reconstruct_probs"]

# [[network]]
# input = "gpu_reconstruct_mix_volume"
# process="split"
# pos=1
# axis=1
# output=["gpu_reconstruct_volume", "gpu_reconstruct_probs"]

[[network]]
input=[ "gpu_volume", "gpu_reconstruct_volume" ]
process="loss.l2_norm_distance"
output="loss_reconstruct_volume"
reduce="no"
test=false

[[network]]
input=[ "gpu_reconstruct_probs", "gpu_label" ]
process="chainer.softmax_cross_entropy"
output="loss_reconstruct_label"
reduce="no"
test=false

[[network]]
input=["loss_reconstruct_volume", "loss_reconstruct_label"]
process="multi_task_combine"
label="multi_task_combine"
output="loss"
test=false

[[network]]
input="loss_reconstruct_volume"
process="chainer.sum"
output="loss_reconstruct_volume_reduce"

[[network]]
input="loss_reconstruct_label"
process="chainer.sum"
output="loss_reconstruct_label_reduce"

[[network]]
input="gpu_reconstruct_probs"
process="chainer.softmax"
output="gpu_reconstruct_label"

[[network]]
input = ["gpu_reconstruct_volume", "gpu_volume"]
process= "diff_image"
output = "diff_volume"
train = false
test = false
absolute = true

# Visualize declaration
[[visualize]]
type  = "image_write"
image_names = [ 
  "volume", "diff_volume", 
  "gpu_reconstruct_volume", "gpu_volume" ,
  "gpu_reconstruct_label", "gpu_label"
]
output_filename = '${visualize_dir}/{__train_iteration__:08d}_{__name__}_{__index__}.mhd'
num_images = 3

